{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from src.rlmcmc.agent import Actor, QNetwork\n",
    "from src.rlmcmc.env import RLMHEnvV33\n",
    "from src.rlmcmc.utils import Args, MCMCAnimation, Toolbox\n",
    "from src.rlmcmc.learning import LearningDDPGRandomCountClipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p = Toolbox.make_log_target_pdf(\n",
    "    \"test-multivariant_normal-test-multivariant_normal\",\n",
    "    \"../../posteriordb/posterior_database\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env setup\n",
    "args = Args()\n",
    "args.env_id = 'RLMHEnv-v3.3'\n",
    "args.seed = 1234\n",
    "args.log_target_pdf = log_p\n",
    "args.total_timesteps = 10_000\n",
    "# args.total_timesteps = 11\n",
    "args.exploration_noise = 0.1\n",
    "args.batch_size = 128\n",
    "# args.learning_starts = args.batch_size\n",
    "args.learning_starts = 1_000\n",
    "args.gamma = 0.99\n",
    "# args.buffer_size = args.total_timesteps\n",
    "args.learning_rate = 1e-5\n",
    "args.policy_frequency = 2\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "# device = torch.device(\"cuda\")\n",
    "\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [\n",
    "        Toolbox.make_env(\n",
    "\n",
    "            env_id=args.env_id,\n",
    "            seed=args.seed,\n",
    "            log_target_pdf=args.log_target_pdf,\n",
    "            sample_dim=args.sample_dim,\n",
    "            total_timesteps=args.total_timesteps\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "predicted_envs = gym.vector.SyncVectorEnv(\n",
    "    [\n",
    "        Toolbox.make_env(\n",
    "\n",
    "            env_id=args.env_id,\n",
    "            seed=args.seed,\n",
    "            log_target_pdf=args.log_target_pdf,\n",
    "            sample_dim=args.sample_dim,\n",
    "            total_timesteps=args.total_timesteps\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Box), \"only continuous action space is supported\"\n",
    "\n",
    "actor = Actor(envs, device).to(device)\n",
    "actor = actor.double()\n",
    "# actor = torch.compile(actor)\n",
    "qf1 = QNetwork(envs).to(device)\n",
    "qf1 = qf1.double()\n",
    "# qf1 = torch.compile(qf1)\n",
    "qf1_target = QNetwork(envs).to(device)\n",
    "qf1_target = qf1_target.double()\n",
    "# qf1_target = torch.compile(qf1_target)\n",
    "target_actor = Actor(envs, device).to(device)\n",
    "target_actor = target_actor.double()\n",
    "# target_actor = torch.compile(target_actor)\n",
    "target_actor.load_state_dict(actor.state_dict())\n",
    "qf1_target.load_state_dict(qf1.state_dict())\n",
    "q_optimizer = optim.Adam(list(qf1.parameters()), lr=args.learning_rate)\n",
    "actor_optimizer = optim.Adam(list(actor.parameters()), lr=args.learning_rate)\n",
    "\n",
    "envs.single_observation_space.dtype = np.float64\n",
    "rb = ReplayBuffer(\n",
    "    args.buffer_size,\n",
    "    envs.single_observation_space,\n",
    "    envs.single_action_space,\n",
    "    device,\n",
    "    handle_timeout_termination=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = LearningDDPGRandomCountClipping(\n",
    "    env=envs,\n",
    "    actor=actor,\n",
    "    target_actor=target_actor,\n",
    "    critic=qf1,\n",
    "    target_critic=qf1_target,\n",
    "    actor_optimizer=actor_optimizer,\n",
    "    critic_optimizer=q_optimizer,\n",
    "    replay_buffer=rb,\n",
    "    total_timesteps=args.total_timesteps,\n",
    "    learning_starts=args.learning_starts,\n",
    "    batch_size=args.batch_size,\n",
    "    exploration_noise=args.exploration_noise,\n",
    "    gamma=args.gamma,\n",
    "    policy_frequency=args.policy_frequency,\n",
    "    tau=args.tau,\n",
    "    seed=args.seed,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99bb0afbda24a34940dd99097eb815a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/congye/Code/PythonProjects/LearningAdaptiveMCMC/experiments/MVN/../../src/rlmcmc/learning/_learning.py:519: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.critic.parameters(), 1.0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_func \u001b[38;5;241m=\u001b[39m \u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient_clipping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/PythonProjects/LearningAdaptiveMCMC/experiments/MVN/../../src/rlmcmc/learning/_learning.py:524\u001b[0m, in \u001b[0;36mLearningDDPGRandom.train\u001b[0;34m(self, gradient_clipping)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m# print(critic_loss.detach().cpu().grad)\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 524\u001b[0m logging\u001b[38;5;241m.\u001b[39mDEBUG(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcritic_grad: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optimizer\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    527\u001b[0m     actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(\n\u001b[1;32m    528\u001b[0m         data\u001b[38;5;241m.\u001b[39mobservations, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(data\u001b[38;5;241m.\u001b[39mobservations)\n\u001b[1;32m    529\u001b[0m     )\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "training_func = learning.train(gradient_clipping=True)\n",
    "# training_func = learning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.count_num_gradient_clipping_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.count_num_gradient_clipping_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_func.plot(critic_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = training_func.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('save/data/training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_func = learning.predict(predicted_envs, 5_000)\n",
    "predict_func.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = predict_func.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.to_csv('save/data/predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_animation = MCMCAnimation(\n",
    "    log_target_pdf=log_p,\n",
    "    dataframe=df_predict,\n",
    "    xlim=(-5, 5),\n",
    "    ylim=(-5, 5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file_path = \"./save/data/MVN01_train.mp4\"\n",
    "mcmc_animation.make().save(anim_file_path, writer='ffmpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.save(\"save/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
